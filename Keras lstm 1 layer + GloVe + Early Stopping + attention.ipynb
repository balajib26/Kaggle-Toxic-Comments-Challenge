{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "582fe746-5914-4b94-8b0b-ba603fc604cd",
    "_uuid": "3e03184d38dfa0b4d3f39de3f4bfe54b44e05dc6"
   },
   "source": [
    "# For introduction look at Keras Introduction+ lstm 1 layer + GloVe + Early Stopping .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "2c09a73b-225c-4cb3-b6e5-8360cfe27bef",
    "_uuid": "461c683283c62f10be20c61a56dfdadc4e38c392",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Bidirectional,LSTM,RepeatVector,TimeDistributed,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization, Flatten, Conv1D, MaxPooling1D,GlobalMaxPool1D,CuDNNLSTM,CuDNNGRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout,SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import initializers,regularizers, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "8ff1b6f1-2e72-4eec-954e-017ced59dce5",
    "_uuid": "2baebccd3836f4bda9b03ac3ea85b2fd511e73c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(153164, 2)\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "\n",
    "#df_train = pd.read_csv('train.csv.zip')\n",
    "#df_test = pd.read_csv('test.csv.zip')\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "20b9b3aa-110b-4c59-9970-1732e87017fa",
    "_uuid": "c4392f8fc9f88c5daef65e66d233b72093de8a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312735, 8)\n"
     ]
    }
   ],
   "source": [
    "# combine the train and test sets for encoding and padding\n",
    "\n",
    "train_len = len(df_train)\n",
    "df_combined =  pd.concat(objs=[df_train, df_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                              comment_text                id  \\\n",
      "0       Explanation\\nWhy the edits made under my usern...  0000997932d777bf   \n",
      "1       D'aww! He matches this background colour I'm s...  000103f0d9cfb60f   \n",
      "2       Hey man, I'm really not trying to edit war. It...  000113f07ec002fd   \n",
      "3       \"\\nMore\\nI can't make any real suggestions on ...  0001b41b1c6bb37e   \n",
      "4       You, sir, are my hero. Any chance you remember...  0001d958c54c6e35   \n",
      "5       \"\\n\\nCongratulations from me as well, use the ...  00025465d4725e87   \n",
      "6            COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK  0002bcb3da6cb337   \n",
      "7       Your vandalism to the Matt Shirvington article...  00031b1e95af7921   \n",
      "8       Sorry if the word 'nonsense' was offensive to ...  00037261f536c51d   \n",
      "9       alignment on this subject and which are contra...  00040093b2687caa   \n",
      "10      \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...  0005300084f90edc   \n",
      "11      bbq \\n\\nbe a man and lets discuss it-maybe ove...  00054a5e18b50dd4   \n",
      "12      Hey... what is it..\\n@ | talk .\\nWhat is it......  0005c987bdfc9d4b   \n",
      "13      Before you start throwing accusations and warn...  0006f16e4e9f292e   \n",
      "14      Oh, and the girl above started her arguments w...  00070ef96486d6f9   \n",
      "15      \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...  00078f8ce7eb276d   \n",
      "16      Bye! \\n\\nDon't look, come or think of comming ...  0007e25b2121310b   \n",
      "17       REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski  000897889268bc93   \n",
      "18      The Mitsurugi point made no sense - why not ar...  0009801bd85e5806   \n",
      "19      Don't mean to bother you \\n\\nI see that you're...  0009eaea3325de8c   \n",
      "20      \"\\n\\n Regarding your recent edits \\n\\nOnce aga...  000b08c464718505   \n",
      "21      \"\\nGood to know. About me, yeah, I'm studying ...  000bfd0867774845   \n",
      "22      \"\\n\\n Snowflakes are NOT always symmetrical! \\...  000c0dfd995809fa   \n",
      "23      \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...  000c6a3f0cd3ba8e   \n",
      "24      \"\\n\\nRe-considering 1st paragraph edit?\\nI don...  000cfee90f50d471   \n",
      "25      Radial symmetry \\n\\nSeveral now extinct lineag...  000eefc67a2c930f   \n",
      "26      There's no need to apologize. A Wikipedia arti...  000f35deef84dc4a   \n",
      "27      Yes, because the mother of the child in the ca...  000ffab30195c5e1   \n",
      "28      \"\\nOk. But it will take a bit of work but I ca...  0010307a3a50a353   \n",
      "29      \"== A barnstar for you! ==\\n\\n  The Real Life ...  0010833a96e1f886   \n",
      "...                                                   ...               ...   \n",
      "312705  \" \\n\\n == Same coffee shop? == \\n\\n My memory ...  fff3ae2e177b6bb3   \n",
      "312706  SO many things wrong with that viewpoint - fro...  fff4109e837f7acc   \n",
      "312707  \" \\n\\n Unless we have an article for some othe...  fff4373a81ef9f2a   \n",
      "312708  Hannah and Maddie are soooooo awesome and are ...  fff460574ddbcd80   \n",
      "312709  :::no problem, I tagged it and cleaned it out....  fff4fc0a1555be5c   \n",
      "312710  :PS I've just looked at the history of this ar...  fff5b9bb944d634c   \n",
      "312711  \"== Your edit to Maungaturoto == \\n Please don...  fff5c4a77fe0c05f   \n",
      "312712  :If you wish to contest the prod, please remov...  fff5fb61bd637c82   \n",
      "312713  Balancing the two approaches to psychiatry ( b...  fff69311f306df44   \n",
      "312714                                 Ah, suck my balls.  fff6ad63666fb304   \n",
      "312715  == Your name mentioned == \\n Hi, I just though...  fff7159b3ee95618   \n",
      "312716  I've just discovered yet another list: List of...  fff718ffe5f05559   \n",
      "312717  ==Wikiproject Video Games assessment== \\n I do...  fff7fc22a0cdccd3   \n",
      "312718  ::Consensus for ruining Wikipedia? I think tha...  fff83b80284d8440   \n",
      "312719  == DAP ?  == \\n\\n What's point with DAP ?! Naz...  fff8ef316d0c6990   \n",
      "312720  shut down the mexican border withought looking...  fff8f521a7dbcd47   \n",
      "312721  :Jerome, I see you never got around to thisâ€¦! ...  fff8f64043129fa2   \n",
      "312722  ==Lucky bastard== \\n http://wikimediafoundatio...  fff9d70fe0722906   \n",
      "312723  ==WTF== \\n It's no longer a redlink.  Now what...  fff9fa508f400ee6   \n",
      "312724  \" \\n\\n ==\"\"Illness\"\" no shit== \\n Just for the...  fffa3fae1890b40a   \n",
      "312725  ==shame on you all!!!== \\n\\n You want to speak...  fffa8a11c4378854   \n",
      "312726  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...  fffac2a094c8e0e2   \n",
      "312727  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...  fffb5451268fb5ba   \n",
      "312728  :Disagree. Soviet railways need their own arti...  fffc2b34bbe61c8d   \n",
      "312729  This idiot can't even use proper grammar when ...  fffc489742ffe69b   \n",
      "312730  . \\n i totally agree, this stuff is nothing bu...  fffcd0960ee309b5   \n",
      "312731  == Throw from out field to home plate. == \\n\\n...  fffd7a9a6eb32c16   \n",
      "312732  \" \\n\\n == Okinotorishima categories == \\n\\n I ...  fffda9e8d6fafa9e   \n",
      "312733  \" \\n\\n == \"\"One of the founding nations of the...  fffe8f1340a79fc2   \n",
      "312734  \" \\n :::Stop already. Your bullshit is not wel...  ffffce3fb183ee80   \n",
      "\n",
      "        identity_hate  insult  obscene  severe_toxic  threat  toxic  \n",
      "0                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "1                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "2                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "3                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "4                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "5                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "6                 0.0     1.0      1.0           1.0     0.0    1.0  \n",
      "7                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "8                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "9                 0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "10                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "11                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "12                0.0     0.0      0.0           0.0     0.0    1.0  \n",
      "13                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "14                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "15                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "16                0.0     0.0      0.0           0.0     0.0    1.0  \n",
      "17                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "18                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "19                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "20                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "21                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "22                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "23                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "24                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "25                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "26                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "27                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "28                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "29                0.0     0.0      0.0           0.0     0.0    0.0  \n",
      "...               ...     ...      ...           ...     ...    ...  \n",
      "312705            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312706            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312707            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312708            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312709            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312710            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312711            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312712            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312713            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312714            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312715            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312716            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312717            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312718            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312719            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312720            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312721            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312722            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312723            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312724            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312725            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312726            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312727            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312728            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312729            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312730            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312731            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312732            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312733            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "312734            NaN     NaN      NaN           NaN     NaN    NaN  \n",
      "\n",
      "[312735 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "0b23211a-fb43-4fe3-a855-86317a7937ce",
    "_uuid": "f5b22283efd3faef27316ea3c65867f688427817",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define text data\n",
    "docs_combined = df_combined['comment_text'].astype(str)\n",
    "\n",
    "# initialize the tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs_combined)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# integer encode the text data\n",
    "encoded_docs = t.texts_to_sequences(docs_combined)\n",
    "\n",
    "# pad the vectors to create uniform length\n",
    "padded_docs_combined = pad_sequences(encoded_docs, maxlen=150, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "210f64cb-5e3c-4e08-90ad-dbbb23b90df8",
    "_uuid": "410ce48a5a51e8ecb2e75bf9ecf9c2473e0b4cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 150)\n",
      "(153164, 150)\n"
     ]
    }
   ],
   "source": [
    "# seperate the train and test sets\n",
    "\n",
    "df_train_padded = padded_docs_combined[:train_len]\n",
    "df_test_padded = padded_docs_combined[train_len:]\n",
    "\n",
    "print(df_train_padded.shape)\n",
    "print(df_test_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "27d6f8a3-415d-460c-8f6a-d21ec5219d21",
    "_uuid": "9ff0edb62e63e13339031f4f9b17c9558bb9cf2d"
   },
   "source": [
    "### **Load the GloVe embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c1ddb595-c6dd-4a10-812e-9528f0489fab",
    "_uuid": "3c7fca0da64ff99701ff9d30223e598046c1ce05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2196016 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the glove840B embedding into memory after downloading and unzippping\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('/home/nbuser/glove/glove.840B.300d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "    # Note: use split(' ') instead of split() if you get an error.\n",
    "\tvalues = line.split(' ')\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# create a weight matrix\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58dfc4cc-01ee-489a-808b-3ff3120125b8",
    "_uuid": "855ccac09de4f92e853cae879089e209e5b57201"
   },
   "source": [
    "### **Define X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "9d242e26-e9a0-4ae3-a47c-97a41e638343",
    "_uuid": "086e9e087dc425b4ff79564680bb47ac55569776",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_train_padded\n",
    "X_test = df_test_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = df_train[list_classes].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b50dbcce-d6a2-4561-932d-8220b18e89f4",
    "_uuid": "774dd49341c23f367e3d4c1e08894bd129fd852b"
   },
   "source": [
    "### **Train and generate predictions for each of the 6 target columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preds = []    \n",
    "# create a stratified split\n",
    "X_train, X_eval, y_train ,y_eval = train_test_split(X, y,test_size=0.2,shuffle=True)\n",
    "                                                    \n",
    "#random_state=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/15.PNG\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/16.PNG\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_DIM = 100\n",
    "\n",
    "class Attention(Layer):\n",
    "\n",
    "    def __init__(self, regularizer=regularizers.l2(1e-10), **kwargs):\n",
    "        self.regularizer = regularizer\n",
    "        self.supports_masking = True\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3        \n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[-1], CONTEXT_DIM),\n",
    "                                 initializer='normal',\n",
    "                                 trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(CONTEXT_DIM,),\n",
    "                                 initializer='normal',\n",
    "                                 trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.u = self.add_weight(name='u',\n",
    "                                 shape=(CONTEXT_DIM,),\n",
    "                                 initializer='normal',\n",
    "                                 trainable=True, \n",
    "                                 regularizer=self.regularizer)        \n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x, dim):\n",
    "        \"\"\"Computes softmax along a specified dim. Keras currently lacks this feature.\n",
    "        \"\"\"\n",
    "        if K.backend() == 'tensorflow':\n",
    "            import tensorflow as tf\n",
    "            return tf.nn.softmax(x, dim)\n",
    "        elif K.backend() == 'theano':\n",
    "            # Theano cannot softmax along an arbitrary dim.\n",
    "            # So, we will shuffle `dim` to -1 and un-shuffle after softmax.\n",
    "            perm = np.arange(K.ndim(x))\n",
    "            perm[dim], perm[-1] = perm[-1], perm[dim]\n",
    "            x_perm = K.permute_dimensions(x, perm)\n",
    "            output = K.softmax(x_perm)\n",
    "\n",
    "            # Permute back\n",
    "            perm[dim], perm[-1] = perm[-1], perm[dim]\n",
    "            output = K.permute_dimensions(x, output)\n",
    "            return output\n",
    "        else:\n",
    "            raise ValueError(\"Backend '{}' not supported\".format(K.backend()))\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ut = K.tanh(K.bias_add(K.dot(x, self.W), self.b)) * self.u\n",
    "\n",
    "        # Collapse `attention_dims` to 1. This indicates the weight for each time_step.\n",
    "        ut = K.sum(ut, axis=-1, keepdims=True)\n",
    "\n",
    "        # Convert those weights into a distribution but along time axis.\n",
    "        # i.e., sum of alphas along `time_steps` axis should be 1.\n",
    "        self.at = self.softmax(ut, dim=1)\n",
    "        if mask is not None:\n",
    "            self.at *= K.cast(K.expand_dims(mask, -1), K.floatx())\n",
    "\n",
    "        # Weighted sum along `time_steps` axis.\n",
    "        return K.sum(x * self.at, axis=-2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(Attention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAIN Create LSTM model\n",
    "#Best performing model-lr=0.0003\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], \n",
    "                  input_length=150, trainable=False))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add((Bidirectional(CuDNNLSTM(50,return_sequences=True))))\n",
    "model.add(Attention())\n",
    "model.add(Dense(70, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 150, 300)          118436400 \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 150, 100)          140800    \n",
      "_________________________________________________________________\n",
      "attention_3 (Attention)      (None, 100)               10200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 70)                7070      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 426       \n",
      "=================================================================\n",
      "Total params: 118,594,896\n",
      "Trainable params: 158,496\n",
      "Non-trainable params: 118,436,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/40\n",
      "127656/127656 [==============================] - 67s 522us/step - loss: 0.0732 - acc: 0.9767 - val_loss: 0.0455 - val_acc: 0.9829\n",
      "Epoch 2/40\n",
      "127656/127656 [==============================] - 66s 515us/step - loss: 0.0460 - acc: 0.9827 - val_loss: 0.0439 - val_acc: 0.9833\n",
      "Epoch 3/40\n",
      "127656/127656 [==============================] - 66s 514us/step - loss: 0.0433 - acc: 0.9833 - val_loss: 0.0433 - val_acc: 0.9836\n",
      "Epoch 4/40\n",
      "127656/127656 [==============================] - 65s 509us/step - loss: 0.0414 - acc: 0.9840 - val_loss: 0.0435 - val_acc: 0.9836\n",
      "Epoch 5/40\n",
      "127656/127656 [==============================] - 65s 509us/step - loss: 0.0399 - acc: 0.9845 - val_loss: 0.0437 - val_acc: 0.9835\n",
      "Epoch 6/40\n",
      " 66816/127656 [==============>...............] - ETA: 28s - loss: 0.0388 - acc: 0.9849"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9023a4e27200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m history = model.fit(X_train, y_train, validation_data=(X_eval, y_eval),\n\u001b[0;32m---> 10\u001b[0;31m                    epochs=40, verbose=1,callbacks=[early_stopping,save_best],batch_size=128)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # compile the model\n",
    "Adam_opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.000015)\n",
    "model.compile(optimizer=Adam_opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, mode='min',min_delta=0.0005)\n",
    "save_best = ModelCheckpoint('/home/nbuser/toxiclstmattention.hdf', save_best_only=True, \n",
    "                           monitor='val_acc', mode='max')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_eval, y_eval),\n",
    "                    epochs=40, verbose=1,callbacks=[early_stopping,save_best],batch_size=128)\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('/home/nbuser/toxiclstmattention.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a prediction on y (target column)\n",
    "    \n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9745911e-01, 5.8220989e-01, 9.7239596e-01, 1.3976243e-01,\n",
       "        9.2421460e-01, 4.4856468e-01],\n",
       "       [9.3540637e-04, 6.0126801e-08, 8.4280065e-05, 1.4785840e-06,\n",
       "        3.9639646e-05, 1.6033798e-06],\n",
       "       [3.8379602e-04, 3.3369105e-08, 3.4451561e-05, 1.0978166e-06,\n",
       "        1.3349451e-05, 9.3679165e-07],\n",
       "       ...,\n",
       "       [1.8271645e-04, 1.0796542e-08, 2.3067649e-05, 2.9302774e-07,\n",
       "        6.5523991e-06, 3.1244323e-07],\n",
       "       [1.9745632e-04, 8.6652975e-08, 1.6009037e-05, 2.9206708e-06,\n",
       "        7.5593130e-06, 1.5606578e-05],\n",
       "       [9.7628772e-01, 1.8008012e-02, 8.5504109e-01, 7.2783773e-04,\n",
       "        6.7450976e-01, 2.4795048e-03]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ce2b8fc7-dc8c-438b-ab91-6723abad0007",
    "_uuid": "60ed543d945f6ba0ea9f4db52f5aa68d6769d69a"
   },
   "source": [
    "### **Create a submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission[list_classes] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"baselinelstmattention.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = pd.read_csv('baselinelstmattention.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>4.432712e-01</td>\n",
       "      <td>9.750918e-01</td>\n",
       "      <td>1.026920e-02</td>\n",
       "      <td>9.394193e-01</td>\n",
       "      <td>4.166672e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>9.601138e-10</td>\n",
       "      <td>5.475502e-06</td>\n",
       "      <td>4.189792e-08</td>\n",
       "      <td>1.766603e-06</td>\n",
       "      <td>2.485000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.099106e-09</td>\n",
       "      <td>3.012348e-06</td>\n",
       "      <td>6.663038e-08</td>\n",
       "      <td>1.019648e-06</td>\n",
       "      <td>3.778804e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6.409814e-11</td>\n",
       "      <td>1.663322e-06</td>\n",
       "      <td>1.807170e-08</td>\n",
       "      <td>3.011706e-07</td>\n",
       "      <td>2.538108e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>2.495954e-06</td>\n",
       "      <td>4.381569e-04</td>\n",
       "      <td>8.765717e-05</td>\n",
       "      <td>1.002813e-04</td>\n",
       "      <td>1.765878e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.419354e-09</td>\n",
       "      <td>2.041784e-06</td>\n",
       "      <td>5.578204e-07</td>\n",
       "      <td>1.354267e-06</td>\n",
       "      <td>5.824378e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2.576459e-09</td>\n",
       "      <td>4.073026e-05</td>\n",
       "      <td>6.135154e-08</td>\n",
       "      <td>3.693880e-05</td>\n",
       "      <td>4.503346e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.426644</td>\n",
       "      <td>1.459220e-04</td>\n",
       "      <td>3.122146e-02</td>\n",
       "      <td>7.474751e-05</td>\n",
       "      <td>2.829204e-02</td>\n",
       "      <td>6.031641e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.065159</td>\n",
       "      <td>1.986716e-06</td>\n",
       "      <td>6.723492e-03</td>\n",
       "      <td>2.475270e-06</td>\n",
       "      <td>9.288167e-03</td>\n",
       "      <td>4.892949e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>5.137209e-09</td>\n",
       "      <td>2.005500e-05</td>\n",
       "      <td>1.180496e-07</td>\n",
       "      <td>4.062455e-06</td>\n",
       "      <td>5.496302e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>0.484893</td>\n",
       "      <td>7.597377e-05</td>\n",
       "      <td>2.699343e-01</td>\n",
       "      <td>1.163435e-05</td>\n",
       "      <td>8.893717e-03</td>\n",
       "      <td>8.660281e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>6.126807e-05</td>\n",
       "      <td>4.723310e-02</td>\n",
       "      <td>3.952305e-05</td>\n",
       "      <td>1.281597e-02</td>\n",
       "      <td>1.017630e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1.380292e-09</td>\n",
       "      <td>1.017005e-05</td>\n",
       "      <td>1.041074e-07</td>\n",
       "      <td>4.258527e-06</td>\n",
       "      <td>7.554525e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>6.192563e-11</td>\n",
       "      <td>3.057511e-06</td>\n",
       "      <td>2.696375e-09</td>\n",
       "      <td>4.182615e-07</td>\n",
       "      <td>2.404665e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>5.638963e-11</td>\n",
       "      <td>1.534680e-06</td>\n",
       "      <td>9.678918e-09</td>\n",
       "      <td>3.348710e-07</td>\n",
       "      <td>3.498119e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>8.980985e-09</td>\n",
       "      <td>1.468674e-05</td>\n",
       "      <td>3.757809e-07</td>\n",
       "      <td>8.891055e-06</td>\n",
       "      <td>1.042390e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>3.427659e-06</td>\n",
       "      <td>3.937315e-04</td>\n",
       "      <td>4.239043e-05</td>\n",
       "      <td>2.938619e-04</td>\n",
       "      <td>9.510299e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>1.463811e-09</td>\n",
       "      <td>8.941905e-06</td>\n",
       "      <td>7.580095e-08</td>\n",
       "      <td>7.979092e-06</td>\n",
       "      <td>4.670340e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>2.854966e-09</td>\n",
       "      <td>3.167087e-05</td>\n",
       "      <td>1.196882e-07</td>\n",
       "      <td>8.359446e-06</td>\n",
       "      <td>3.616867e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>4.734531e-07</td>\n",
       "      <td>1.230040e-04</td>\n",
       "      <td>1.080620e-05</td>\n",
       "      <td>7.409057e-05</td>\n",
       "      <td>1.469602e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>2.105523e-06</td>\n",
       "      <td>1.073072e-03</td>\n",
       "      <td>2.129374e-05</td>\n",
       "      <td>1.878606e-04</td>\n",
       "      <td>2.578232e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>0.655560</td>\n",
       "      <td>1.568434e-03</td>\n",
       "      <td>5.233712e-02</td>\n",
       "      <td>1.706190e-03</td>\n",
       "      <td>4.671603e-02</td>\n",
       "      <td>1.344147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>0.013747</td>\n",
       "      <td>1.386062e-05</td>\n",
       "      <td>7.871939e-04</td>\n",
       "      <td>2.030810e-04</td>\n",
       "      <td>9.272313e-04</td>\n",
       "      <td>3.912749e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>1.470974e-08</td>\n",
       "      <td>2.456671e-05</td>\n",
       "      <td>1.010433e-06</td>\n",
       "      <td>1.514081e-05</td>\n",
       "      <td>1.792487e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>0.459992</td>\n",
       "      <td>5.438656e-04</td>\n",
       "      <td>1.603590e-01</td>\n",
       "      <td>8.503631e-04</td>\n",
       "      <td>5.103083e-02</td>\n",
       "      <td>5.268381e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.550566e-10</td>\n",
       "      <td>3.396829e-06</td>\n",
       "      <td>3.701259e-09</td>\n",
       "      <td>6.803175e-07</td>\n",
       "      <td>1.404778e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>1.236463e-09</td>\n",
       "      <td>7.905967e-06</td>\n",
       "      <td>1.012921e-07</td>\n",
       "      <td>2.401799e-06</td>\n",
       "      <td>1.865887e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>0.026828</td>\n",
       "      <td>1.301571e-06</td>\n",
       "      <td>4.658954e-04</td>\n",
       "      <td>3.149077e-06</td>\n",
       "      <td>2.314002e-03</td>\n",
       "      <td>7.744211e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>0.260050</td>\n",
       "      <td>2.829312e-04</td>\n",
       "      <td>3.688398e-03</td>\n",
       "      <td>3.248741e-04</td>\n",
       "      <td>1.943753e-02</td>\n",
       "      <td>1.209158e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>1.257538e-08</td>\n",
       "      <td>4.253220e-05</td>\n",
       "      <td>5.610000e-07</td>\n",
       "      <td>2.128572e-05</td>\n",
       "      <td>1.874916e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153134</th>\n",
       "      <td>fff3ae2e177b6bb3</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>6.871996e-10</td>\n",
       "      <td>6.899103e-06</td>\n",
       "      <td>3.946771e-08</td>\n",
       "      <td>1.986737e-06</td>\n",
       "      <td>1.297407e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153135</th>\n",
       "      <td>fff4109e837f7acc</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>6.573653e-08</td>\n",
       "      <td>3.533084e-05</td>\n",
       "      <td>9.972056e-07</td>\n",
       "      <td>4.193405e-05</td>\n",
       "      <td>5.543376e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153136</th>\n",
       "      <td>fff4373a81ef9f2a</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>3.934539e-10</td>\n",
       "      <td>1.060995e-05</td>\n",
       "      <td>4.348947e-09</td>\n",
       "      <td>1.597625e-06</td>\n",
       "      <td>1.028386e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153137</th>\n",
       "      <td>fff460574ddbcd80</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>7.139032e-09</td>\n",
       "      <td>1.856042e-05</td>\n",
       "      <td>3.962128e-07</td>\n",
       "      <td>1.598751e-05</td>\n",
       "      <td>2.481476e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153138</th>\n",
       "      <td>fff4fc0a1555be5c</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>4.562894e-09</td>\n",
       "      <td>1.822337e-05</td>\n",
       "      <td>1.772127e-07</td>\n",
       "      <td>6.672884e-06</td>\n",
       "      <td>9.370337e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153139</th>\n",
       "      <td>fff5b9bb944d634c</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>1.970021e-09</td>\n",
       "      <td>1.011090e-05</td>\n",
       "      <td>4.622541e-08</td>\n",
       "      <td>8.739458e-06</td>\n",
       "      <td>4.021925e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153140</th>\n",
       "      <td>fff5c4a77fe0c05f</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>2.841391e-09</td>\n",
       "      <td>5.684289e-06</td>\n",
       "      <td>1.435234e-07</td>\n",
       "      <td>3.811381e-06</td>\n",
       "      <td>5.604547e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>fff5fb61bd637c82</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.100404e-10</td>\n",
       "      <td>1.304906e-06</td>\n",
       "      <td>9.040622e-09</td>\n",
       "      <td>3.129484e-07</td>\n",
       "      <td>4.694565e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153142</th>\n",
       "      <td>fff69311f306df44</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>2.163895e-07</td>\n",
       "      <td>1.072590e-04</td>\n",
       "      <td>3.578591e-06</td>\n",
       "      <td>1.429906e-04</td>\n",
       "      <td>1.369990e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153143</th>\n",
       "      <td>fff6ad63666fb304</td>\n",
       "      <td>0.995376</td>\n",
       "      <td>1.432240e-01</td>\n",
       "      <td>9.683400e-01</td>\n",
       "      <td>1.776592e-04</td>\n",
       "      <td>4.677789e-01</td>\n",
       "      <td>5.890711e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>fff7159b3ee95618</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>8.866678e-08</td>\n",
       "      <td>3.882981e-05</td>\n",
       "      <td>6.499461e-06</td>\n",
       "      <td>6.704601e-05</td>\n",
       "      <td>9.844213e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>fff718ffe5f05559</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>1.113253e-07</td>\n",
       "      <td>1.442160e-04</td>\n",
       "      <td>1.722718e-07</td>\n",
       "      <td>9.786338e-05</td>\n",
       "      <td>5.873448e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>fff7fc22a0cdccd3</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2.656291e-11</td>\n",
       "      <td>5.768139e-07</td>\n",
       "      <td>8.582311e-09</td>\n",
       "      <td>2.271084e-07</td>\n",
       "      <td>1.239370e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>fff83b80284d8440</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>2.301328e-08</td>\n",
       "      <td>5.135697e-05</td>\n",
       "      <td>1.826493e-06</td>\n",
       "      <td>3.257090e-05</td>\n",
       "      <td>3.063789e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>fff8ef316d0c6990</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>5.330232e-08</td>\n",
       "      <td>7.314281e-05</td>\n",
       "      <td>1.680190e-07</td>\n",
       "      <td>3.345513e-05</td>\n",
       "      <td>2.284858e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>fff8f521a7dbcd47</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>3.561607e-03</td>\n",
       "      <td>1.898306e-01</td>\n",
       "      <td>4.781247e-04</td>\n",
       "      <td>1.428232e-01</td>\n",
       "      <td>1.583436e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>2.495341e-10</td>\n",
       "      <td>2.925929e-06</td>\n",
       "      <td>1.573800e-08</td>\n",
       "      <td>1.112201e-06</td>\n",
       "      <td>4.696307e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.894155</td>\n",
       "      <td>1.361758e-02</td>\n",
       "      <td>6.393890e-01</td>\n",
       "      <td>6.883040e-04</td>\n",
       "      <td>5.769854e-01</td>\n",
       "      <td>5.952519e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>fff9fa508f400ee6</td>\n",
       "      <td>0.737509</td>\n",
       "      <td>7.451235e-03</td>\n",
       "      <td>5.237085e-01</td>\n",
       "      <td>2.894317e-04</td>\n",
       "      <td>5.821278e-02</td>\n",
       "      <td>5.424046e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>fffa3fae1890b40a</td>\n",
       "      <td>0.857726</td>\n",
       "      <td>1.564956e-02</td>\n",
       "      <td>7.506506e-01</td>\n",
       "      <td>1.859098e-02</td>\n",
       "      <td>2.188915e-01</td>\n",
       "      <td>4.584328e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.764440</td>\n",
       "      <td>1.197305e-03</td>\n",
       "      <td>5.178462e-02</td>\n",
       "      <td>3.303249e-04</td>\n",
       "      <td>1.113563e-01</td>\n",
       "      <td>2.135070e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>3.257709e-01</td>\n",
       "      <td>9.724534e-01</td>\n",
       "      <td>1.127059e-03</td>\n",
       "      <td>9.405516e-01</td>\n",
       "      <td>7.694745e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>7.154562e-08</td>\n",
       "      <td>7.117853e-05</td>\n",
       "      <td>2.376664e-07</td>\n",
       "      <td>3.694219e-05</td>\n",
       "      <td>1.942292e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>fffc2b34bbe61c8d</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>1.365647e-08</td>\n",
       "      <td>6.563799e-05</td>\n",
       "      <td>1.471082e-07</td>\n",
       "      <td>6.259071e-05</td>\n",
       "      <td>2.014814e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>fffc489742ffe69b</td>\n",
       "      <td>0.875209</td>\n",
       "      <td>6.240387e-03</td>\n",
       "      <td>3.375704e-01</td>\n",
       "      <td>2.284622e-04</td>\n",
       "      <td>6.695580e-01</td>\n",
       "      <td>4.633530e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.536613</td>\n",
       "      <td>3.996025e-05</td>\n",
       "      <td>2.097589e-01</td>\n",
       "      <td>8.318498e-06</td>\n",
       "      <td>1.277541e-02</td>\n",
       "      <td>1.031971e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>5.137119e-07</td>\n",
       "      <td>2.982356e-04</td>\n",
       "      <td>2.294641e-05</td>\n",
       "      <td>3.740016e-04</td>\n",
       "      <td>5.254188e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>3.863895e-10</td>\n",
       "      <td>1.694520e-05</td>\n",
       "      <td>1.190766e-08</td>\n",
       "      <td>4.244228e-06</td>\n",
       "      <td>2.436406e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>3.349958e-08</td>\n",
       "      <td>1.808589e-05</td>\n",
       "      <td>9.213371e-07</td>\n",
       "      <td>3.185072e-05</td>\n",
       "      <td>2.260181e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.987340</td>\n",
       "      <td>2.164761e-02</td>\n",
       "      <td>8.851316e-01</td>\n",
       "      <td>2.736486e-04</td>\n",
       "      <td>5.660080e-01</td>\n",
       "      <td>1.912335e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic       obscene        threat  \\\n",
       "0       00001cee341fdb12  0.999612  4.432712e-01  9.750918e-01  1.026920e-02   \n",
       "1       0000247867823ef7  0.000064  9.601138e-10  5.475502e-06  4.189792e-08   \n",
       "2       00013b17ad220c46  0.000035  1.099106e-09  3.012348e-06  6.663038e-08   \n",
       "3       00017563c3f7919a  0.000005  6.409814e-11  1.663322e-06  1.807170e-08   \n",
       "4       00017695ad8997eb  0.005163  2.495954e-06  4.381569e-04  8.765717e-05   \n",
       "5       0001ea8717f6de06  0.000016  1.419354e-09  2.041784e-06  5.578204e-07   \n",
       "6       00024115d4cbde0f  0.000538  2.576459e-09  4.073026e-05  6.135154e-08   \n",
       "7       000247e83dcc1211  0.426644  1.459220e-04  3.122146e-02  7.474751e-05   \n",
       "8       00025358d4737918  0.065159  1.986716e-06  6.723492e-03  2.475270e-06   \n",
       "9       00026d1092fe71cc  0.000134  5.137209e-09  2.005500e-05  1.180496e-07   \n",
       "10      0002eadc3b301559  0.484893  7.597377e-05  2.699343e-01  1.163435e-05   \n",
       "11      0002f87b16116a7f  0.225806  6.126807e-05  4.723310e-02  3.952305e-05   \n",
       "12      0003806b11932181  0.000194  1.380292e-09  1.017005e-05  1.041074e-07   \n",
       "13      0003e1cccfd5a40a  0.000015  6.192563e-11  3.057511e-06  2.696375e-09   \n",
       "14      00059ace3e3e9a53  0.000013  5.638963e-11  1.534680e-06  9.678918e-09   \n",
       "15      000634272d0d44eb  0.000184  8.980985e-09  1.468674e-05  3.757809e-07   \n",
       "16      000663aff0fffc80  0.004261  3.427659e-06  3.937315e-04  4.239043e-05   \n",
       "17      000689dd34e20979  0.000425  1.463811e-09  8.941905e-06  7.580095e-08   \n",
       "18      000834769115370c  0.000321  2.854966e-09  3.167087e-05  1.196882e-07   \n",
       "19      000844b52dee5f3f  0.001437  4.734531e-07  1.230040e-04  1.080620e-05   \n",
       "20      00084da5d4ead7aa  0.006472  2.105523e-06  1.073072e-03  2.129374e-05   \n",
       "21      00091c35fa9d0465  0.655560  1.568434e-03  5.233712e-02  1.706190e-03   \n",
       "22      000968ce11f5ee34  0.013747  1.386062e-05  7.871939e-04  2.030810e-04   \n",
       "23      0009734200a85047  0.000502  1.470974e-08  2.456671e-05  1.010433e-06   \n",
       "24      00097b6214686db5  0.459992  5.438656e-04  1.603590e-01  8.503631e-04   \n",
       "25      0009aef4bd9e1697  0.000047  1.550566e-10  3.396829e-06  3.701259e-09   \n",
       "26      000a02d807ae0254  0.000057  1.236463e-09  7.905967e-06  1.012921e-07   \n",
       "27      000a6c6d4e89b9bc  0.026828  1.301571e-06  4.658954e-04  3.149077e-06   \n",
       "28      000bafe2080bba82  0.260050  2.829312e-04  3.688398e-03  3.248741e-04   \n",
       "29      000bf0a9894b2807  0.000346  1.257538e-08  4.253220e-05  5.610000e-07   \n",
       "...                  ...       ...           ...           ...           ...   \n",
       "153134  fff3ae2e177b6bb3  0.000096  6.871996e-10  6.899103e-06  3.946771e-08   \n",
       "153135  fff4109e837f7acc  0.000792  6.573653e-08  3.533084e-05  9.972056e-07   \n",
       "153136  fff4373a81ef9f2a  0.000054  3.934539e-10  1.060995e-05  4.348947e-09   \n",
       "153137  fff460574ddbcd80  0.000396  7.139032e-09  1.856042e-05  3.962128e-07   \n",
       "153138  fff4fc0a1555be5c  0.000361  4.562894e-09  1.822337e-05  1.772127e-07   \n",
       "153139  fff5b9bb944d634c  0.000206  1.970021e-09  1.011090e-05  4.622541e-08   \n",
       "153140  fff5c4a77fe0c05f  0.000092  2.841391e-09  5.684289e-06  1.435234e-07   \n",
       "153141  fff5fb61bd637c82  0.000011  1.100404e-10  1.304906e-06  9.040622e-09   \n",
       "153142  fff69311f306df44  0.001461  2.163895e-07  1.072590e-04  3.578591e-06   \n",
       "153143  fff6ad63666fb304  0.995376  1.432240e-01  9.683400e-01  1.776592e-04   \n",
       "153144  fff7159b3ee95618  0.000894  8.866678e-08  3.882981e-05  6.499461e-06   \n",
       "153145  fff718ffe5f05559  0.000929  1.113253e-07  1.442160e-04  1.722718e-07   \n",
       "153146  fff7fc22a0cdccd3  0.000010  2.656291e-11  5.768139e-07  8.582311e-09   \n",
       "153147  fff83b80284d8440  0.002561  2.301328e-08  5.135697e-05  1.826493e-06   \n",
       "153148  fff8ef316d0c6990  0.000785  5.330232e-08  7.314281e-05  1.680190e-07   \n",
       "153149  fff8f521a7dbcd47  0.856881  3.561607e-03  1.898306e-01  4.781247e-04   \n",
       "153150  fff8f64043129fa2  0.000051  2.495341e-10  2.925929e-06  1.573800e-08   \n",
       "153151  fff9d70fe0722906  0.894155  1.361758e-02  6.393890e-01  6.883040e-04   \n",
       "153152  fff9fa508f400ee6  0.737509  7.451235e-03  5.237085e-01  2.894317e-04   \n",
       "153153  fffa3fae1890b40a  0.857726  1.564956e-02  7.506506e-01  1.859098e-02   \n",
       "153154  fffa8a11c4378854  0.764440  1.197305e-03  5.178462e-02  3.303249e-04   \n",
       "153155  fffac2a094c8e0e2  0.999612  3.257709e-01  9.724534e-01  1.127059e-03   \n",
       "153156  fffb5451268fb5ba  0.001836  7.154562e-08  7.117853e-05  2.376664e-07   \n",
       "153157  fffc2b34bbe61c8d  0.001063  1.365647e-08  6.563799e-05  1.471082e-07   \n",
       "153158  fffc489742ffe69b  0.875209  6.240387e-03  3.375704e-01  2.284622e-04   \n",
       "153159  fffcd0960ee309b5  0.536613  3.996025e-05  2.097589e-01  8.318498e-06   \n",
       "153160  fffd7a9a6eb32c16  0.008208  5.137119e-07  2.982356e-04  2.294641e-05   \n",
       "153161  fffda9e8d6fafa9e  0.000168  3.863895e-10  1.694520e-05  1.190766e-08   \n",
       "153162  fffe8f1340a79fc2  0.000776  3.349958e-08  1.808589e-05  9.213371e-07   \n",
       "153163  ffffce3fb183ee80  0.987340  2.164761e-02  8.851316e-01  2.736486e-04   \n",
       "\n",
       "              insult  identity_hate  \n",
       "0       9.394193e-01   4.166672e-01  \n",
       "1       1.766603e-06   2.485000e-07  \n",
       "2       1.019648e-06   3.778804e-07  \n",
       "3       3.011706e-07   2.538108e-08  \n",
       "4       1.002813e-04   1.765878e-05  \n",
       "5       1.354267e-06   5.824378e-07  \n",
       "6       3.693880e-05   4.503346e-07  \n",
       "7       2.829204e-02   6.031641e-04  \n",
       "8       9.288167e-03   4.892949e-05  \n",
       "9       4.062455e-06   5.496302e-07  \n",
       "10      8.893717e-03   8.660281e-05  \n",
       "11      1.281597e-02   1.017630e-02  \n",
       "12      4.258527e-06   7.554525e-07  \n",
       "13      4.182615e-07   2.404665e-08  \n",
       "14      3.348710e-07   3.498119e-08  \n",
       "15      8.891055e-06   1.042390e-06  \n",
       "16      2.938619e-04   9.510299e-05  \n",
       "17      7.979092e-06   4.670340e-07  \n",
       "18      8.359446e-06   3.616867e-07  \n",
       "19      7.409057e-05   1.469602e-05  \n",
       "20      1.878606e-04   2.578232e-05  \n",
       "21      4.671603e-02   1.344147e-01  \n",
       "22      9.272313e-04   3.912749e-03  \n",
       "23      1.514081e-05   1.792487e-06  \n",
       "24      5.103083e-02   5.268381e-03  \n",
       "25      6.803175e-07   1.404778e-07  \n",
       "26      2.401799e-06   1.865887e-07  \n",
       "27      2.314002e-03   7.744211e-05  \n",
       "28      1.943753e-02   1.209158e-01  \n",
       "29      2.128572e-05   1.874916e-06  \n",
       "...              ...            ...  \n",
       "153134  1.986737e-06   1.297407e-07  \n",
       "153135  4.193405e-05   5.543376e-05  \n",
       "153136  1.597625e-06   1.028386e-07  \n",
       "153137  1.598751e-05   2.481476e-06  \n",
       "153138  6.672884e-06   9.370337e-07  \n",
       "153139  8.739458e-06   4.021925e-07  \n",
       "153140  3.811381e-06   5.604547e-07  \n",
       "153141  3.129484e-07   4.694565e-08  \n",
       "153142  1.429906e-04   1.369990e-05  \n",
       "153143  4.677789e-01   5.890711e-03  \n",
       "153144  6.704601e-05   9.844213e-06  \n",
       "153145  9.786338e-05   5.873448e-05  \n",
       "153146  2.271084e-07   1.239370e-08  \n",
       "153147  3.257090e-05   3.063789e-06  \n",
       "153148  3.345513e-05   2.284858e-05  \n",
       "153149  1.428232e-01   1.583436e-01  \n",
       "153150  1.112201e-06   4.696307e-07  \n",
       "153151  5.769854e-01   5.952519e-03  \n",
       "153152  5.821278e-02   5.424046e-03  \n",
       "153153  2.188915e-01   4.584328e-03  \n",
       "153154  1.113563e-01   2.135070e-01  \n",
       "153155  9.405516e-01   7.694745e-01  \n",
       "153156  3.694219e-05   1.942292e-05  \n",
       "153157  6.259071e-05   2.014814e-06  \n",
       "153158  6.695580e-01   4.633530e-03  \n",
       "153159  1.277541e-02   1.031971e-04  \n",
       "153160  3.740016e-04   5.254188e-05  \n",
       "153161  4.244228e-06   2.436406e-07  \n",
       "153162  3.185072e-05   2.260181e-04  \n",
       "153163  5.660080e-01   1.912335e-03  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = predictions[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-34b943bd49e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# append the prediction to a python list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "# append the prediction to a python list\n",
    "preds.append(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1cce236f-c2a8-4a49-af46-e3f757d2a96b",
    "_uuid": "34d25b09fe313b0d94aabb0849929512e5c7f803",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_results = pd.DataFrame({'id':df_test.id,\n",
    "                            \"toxic\":preds[0],\n",
    "                           \"severe_toxic\":preds[1],\n",
    "                           \"obscene\":preds[2],\n",
    "                           \"threat\":preds[3],\n",
    "                           \"insult\":preds[4],\n",
    "                           \"identity_hate\":preds[5]}).set_index('id')\n",
    "\n",
    "# Pandas automatically sorts the columns alphabetically by column name.\n",
    "# Therefore, we need to re-order the columns to match the sample submission file.\n",
    "#df_results = df_results[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult','identity_hate']]\n",
    "\n",
    "# create a submission csv file\n",
    "#df_results.to_csv('kaggle_submission.csv', \n",
    "                  #columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "400a186c-1b13-4680-8416-a061e4672258",
    "_uuid": "f7a3b6cf0c539d64d92ea2741c9ed069b6cc73cb"
   },
   "source": [
    "***\n",
    "### **Resources**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21843050-dee8-46f5-8410-40fd99f1404c",
    "_uuid": "b187960941b6c7be32720261a987fcc489953d1b"
   },
   "source": [
    "These are a few cnn and nlp resources I found helpful:\n",
    "\n",
    "- What are word embeddings?<br>\n",
    "https://www.youtube.com/watch?v=Eku_pbZ3-Mw\n",
    "\n",
    "\n",
    "- Blog post with a simple example explaining how to use pre trained embeddings:<br>https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "\n",
    "- Online cnn course:<br>\n",
    "https://www.coursera.org/learn/convolutional-neural-networks<br>\n",
    "This course can be taken for free. \n",
    "\n",
    "\n",
    "- Lesson 5 notes from the fast.ai course:<br>\n",
    "http://wiki.fast.ai/index.php/Lesson_5_Notes\n",
    "\n",
    "\n",
    "- GloVe: Global Vectors for Word Representation<br>\n",
    "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014.<br>\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "\n",
    "- Machine learning with text<br>\n",
    "https://www.youtube.com/watch?v=ZiKMIuYidY0\n",
    "\n",
    "\n",
    "- NLTK Tutorial series<br>\n",
    "https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "490b224a-22db-4135-bf9f-3f65886c2994",
    "_uuid": "9939b4da27ecece2944fb217e19a8520c65c2ddc"
   },
   "source": [
    "***\n",
    "This competition is a great learning experience. Thank you to all who have been commenting and publishing.\n",
    "\n",
    "Happy new year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "98c3d980-6862-4e7f-99a8-134a48fcc99f",
    "_uuid": "562e4ee4a08ea5f3b47d157cd6443e4a51b0b05c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
